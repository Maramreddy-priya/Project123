{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f886df57-f0fa-48a1-b27d-6e0eaa00bb00",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DateType, FloatType\n",
    "from pyspark.sql.functions import round, col\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "spark = SparkSession.builder.appName('ProjectInsurance').getOrCreate()\n",
    "\n",
    "spark.conf.set(\"fs.azure.account.key.pprojecthealthcare456.dfs.core.windows.net\", \"EKJeYMicvDEsPEIdi+gJzlc0KxwsUivTTIVR2jHeEBM79z1Cd7cOEP0Z5UVv0/QlcYwrBHsrdBm3+AStDru99w==\")\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"sex\", StringType(), True),\n",
    "    StructField(\"bmi\", FloatType(), True),\n",
    "    StructField(\"children\", IntegerType(), True),\n",
    "    StructField(\"smoker\", StringType(), True),\n",
    "    StructField(\"region\", StringType(), True),\n",
    "    StructField(\"charges\", FloatType(), True)\n",
    "])\n",
    "\n",
    "Healthcare_schema = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema) \\\n",
    "    .csv(\"abfss://raw@pprojecthealthcare456.dfs.core.windows.net/insurance.csv\")\n",
    "\n",
    "Insurance = Healthcare_schema.withColumnRenamed(\"age\", \"Age\") \\\n",
    "    .withColumnRenamed(\"sex\", \"Sex\") \\\n",
    "    .withColumnRenamed(\"bmi\", \"BMI\") \\\n",
    "    .withColumnRenamed(\"children\", \"Children\") \\\n",
    "    .withColumnRenamed(\"smoker\", \"Smoker\") \\\n",
    "    .withColumnRenamed(\"region\", \"Region\") \\\n",
    "    .withColumnRenamed(\"charges\", \"Charges\")\n",
    "\n",
    "# Filter to get age greater than 18\n",
    "filtered_df = Insurance.filter(Insurance['Age'] > 18)\n",
    "\n",
    "df_new = Insurance.withColumn('rounded_charges', round(Insurance.Charges, 0))\n",
    "\n",
    "# Filter to get Charges greater than 10000\n",
    "df_new = df_new.filter(col('rounded_charges') >= 10000)\n",
    "\n",
    "\n",
    "# Count rows where 'Smoker' = no and 'Smoker' > yes\n",
    "cnt_cond = lambda cond: F.sum(F.when(cond, 1).otherwise(0))\n",
    "result = df_new.groupBy('Region').agg(\n",
    "    cnt_cond(F.col('Smoker') == 'no').alias('non-smoker_cnt'),\n",
    "    cnt_cond(F.col('Smoker') == 'yes').alias('smoker_cnt')\n",
    ")\n",
    "\n",
    "\n",
    "df_new.repartition(1).write.mode(\"overwrite\").option(\"header\",\"true\").csv(\"abfss://processed@pprojecthealthcare456.dfs.core.windows.net/insurance_transformed.csv\")\n",
    "result.repartition(1).write.mode(\"overwrite\").option(\"header\",\"true\").csv(\"abfss://processed@pprojecthealthcare456.dfs.core.windows.net/insurance_Filter.csv\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3632488780349312,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "project Notebook 2024-06-07 01:43:18",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
